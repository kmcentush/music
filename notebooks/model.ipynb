{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost as cb\n",
    "import polars as pl\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify features and target\n",
    "NUMERIC_FEATURES = [\n",
    "    \"acousticness\",\n",
    "    \"energy\",\n",
    "    \"loudness\",\n",
    "    \"speechiness\",\n",
    "    \"danceability\",\n",
    "    \"instrumentalness\",\n",
    "    \"liveness\",\n",
    "    \"mode\",\n",
    "    \"tempo\",\n",
    "    \"valence\",\n",
    "]\n",
    "OHE_FEATURES = [\n",
    "    \"key\",\n",
    "    \"time_signature\",\n",
    "]\n",
    "TARGET = \"playlist_name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "features = pl.read_parquet(\"features.parquet\")\n",
    "playlists = pl.read_parquet(\"playlists.parquet\")\n",
    "\n",
    "# Join\n",
    "raw = playlists.join(features, left_on=[\"track_id\", \"track_name\"], right_on=[\"id\", \"track\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df: pl.DataFrame, train_fraction: float = 0.8) -> tuple[pl.DataFrame, pl.DataFrame]:\n",
    "    # Note: also works with pl.LazyFrame\n",
    "    df = df.with_columns(pl.all().shuffle(seed=1)).with_row_index(\"_row\")\n",
    "    df_train = df.filter(pl.col(\"_row\") < pl.col(\"_row\").max() * train_fraction)\n",
    "    df_test = df.filter(pl.col(\"_row\") >= pl.col(\"_row\").max() * train_fraction)\n",
    "    return df_train.drop(\"_row\"), df_test.drop(\"_row\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OHE features and target\n",
    "df = raw.to_dummies([*OHE_FEATURES, TARGET])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get column info\n",
    "feature_cols = NUMERIC_FEATURES + [c for ohe_col in OHE_FEATURES for c in df.columns if c.startswith(ohe_col)]\n",
    "num_features = len(feature_cols)\n",
    "class_cols = [c for c in df.columns if c.startswith(TARGET)]\n",
    "num_classes = len(class_cols)\n",
    "\n",
    "num_features, num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "df_train, df_test = train_test_split(df[[*feature_cols, *class_cols]], 0.8)\n",
    "\n",
    "# Split into X and y\n",
    "X_train = df_train[feature_cols]\n",
    "X_test = df_test[feature_cols]\n",
    "y_train = df_train[class_cols]\n",
    "y_test = df_test[class_cols]\n",
    "\n",
    "# Get datasets\n",
    "ds_train = df_train.to_torch(\"dataset\", label=class_cols, dtype=pl.Float32)\n",
    "ds_test = df_test.to_torch(\"dataset\", label=class_cols, dtype=pl.Float32)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get device\n",
    "# TODO: enable CUDA\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "# Define model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(num_features, 16),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16, 32),\n",
    "    nn.ReLU(),\n",
    "    # nn.Linear(32, 32),\n",
    "    # nn.ReLU(),\n",
    "    nn.Linear(32, 16),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16, num_classes),\n",
    ").to(device)\n",
    "\n",
    "# Define criterion and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify training parameters\n",
    "num_epochs = 16\n",
    "batch_size = 16\n",
    "batches_per_epoch = len(ds_train) // batch_size\n",
    "\n",
    "# Initialize dataloaders\n",
    "dl_train = DataLoader(ds_train, batch_size=batch_size, shuffle=True)\n",
    "dl_test = DataLoader(ds_test, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Train model\n",
    "model.train()  # set to training mode\n",
    "for epoch in range(num_epochs):\n",
    "    with tqdm(total=len(dl_train), desc=f\"Epoch {epoch + 1}\", unit=\"batch\") as bar:\n",
    "        for i, (X, y) in enumerate(dl_train):\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward + backward + optimize\n",
    "            y_pred = model(X)\n",
    "            loss = criterion(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            acc = (torch.argmax(y_pred, 1) == torch.argmax(y, 1)).float().mean()\n",
    "\n",
    "            # Update bar\n",
    "            bar.update(i)\n",
    "            bar.set_postfix({\"CrossEntropyLoss\": f\"{loss:.3f}\", \"Accuracy\": f\"{acc:.3f}\"})\n",
    "\n",
    "    # TODO: save best weights based on test set: https://machinelearningmastery.com/building-a-multiclass-classification-model-in-pytorch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare to score\n",
    "model.eval()  # set to evaluation mode\n",
    "pred_train = model(X_train.to_torch(dtype=pl.Float32))\n",
    "pred_test = model(X_test.to_torch(dtype=pl.Float32))\n",
    "true_train = y_train.to_torch(dtype=pl.Float32)\n",
    "true_test = y_test.to_torch(dtype=pl.Float32)\n",
    "\n",
    "# Score\n",
    "ce_train = criterion(pred_train, true_train)\n",
    "ce_test = criterion(pred_test, true_test)\n",
    "acc_train = (torch.argmax(pred_train, 1) == torch.argmax(true_train, 1)).float().mean()\n",
    "acc_test = (torch.argmax(pred_test, 1) == torch.argmax(true_test, 1)).float().mean()\n",
    "\n",
    "print(f\"Train - CrossEntropyLoss: {ce_train:.3f}, Accuracy: {acc_train:.3f}\")\n",
    "print(f\"Test - CrossEntropyLoss: {ce_test:.3f}, Accuracy: {acc_test:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "# CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "df = raw.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get column info\n",
    "feature_cols = NUMERIC_FEATURES + OHE_FEATURES\n",
    "num_features = len(feature_cols)\n",
    "class_col = TARGET\n",
    "num_classes = len(df[class_col].unique())\n",
    "\n",
    "num_features, num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "df_train, df_test = train_test_split(df[[*feature_cols, class_col]], 0.8)\n",
    "\n",
    "# Split into X and y\n",
    "X_train = df_train[feature_cols].to_numpy()\n",
    "X_test = df_test[feature_cols].to_numpy()\n",
    "y_train = df_train[class_col].to_numpy()\n",
    "y_test = df_test[class_col].to_numpy()\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "model = cb.CatBoostClassifier(\n",
    "    iterations=1024,\n",
    "    early_stopping_rounds=16,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "model.fit(X_train, y_train, eval_set=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare to score\n",
    "pred_train = model.predict(X_train)[:, 0]\n",
    "pred_test = model.predict(X_test)[:, 0]\n",
    "true_train = y_train\n",
    "true_test = y_test\n",
    "\n",
    "# Score\n",
    "acc_train = (pred_train == true_train).mean()\n",
    "acc_test = (pred_test == true_test).mean()\n",
    "\n",
    "print(f\"Train - Accuracy: {acc_train:.3f}\")\n",
    "print(f\"Test - Accuracy: {acc_test:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
